{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b569f09",
   "metadata": {},
   "source": [
    "# TP 4 : Optimisation et unittesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e4c62",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "De nombreuses applications nécessitent l'utilisation de matrices de très grande taille. Avec par exemple des millions de lignes et de colonnes. C'est nottament le cas en sciences et ingénierie lors de la résolution d'équations aux dérivées partielles (EDPs), par exemple avec la méthode des éléments finis. Par chance, ces très grandes matrices contiennent une large majorité de zéros. C'est ce que l'on appelle des **matrices creuse** (sparse) en anglais.\n",
    "Ainsi, leur facteur de remplissage est inférieure à 1%. Par exemple, on représente ci-dessous les valeurs non nulles d'une matrice d'éléments finis.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8a/Finite_element_sparse_matrix.png?uselang=fr\" alt=\"sparse-mat\" width=\"400\" height=\"200\">\n",
    "\n",
    "Puisqu'il y a en fait très peu d'information à stoquer, c'est à dire les éléments non nuls de la matrice, on ne va pas utiliser des tableaux numpy de taille (n,m) (dit \"plein\") mais une format spécifique. Parmis les plus classiques, on va implémenter le format **COO** (coordinate list) qui n'est forcément le plus efficace mais qui présente de bonnes performances. Il se présente de la façon suivante: \n",
    "> pour chaque valeur non nulle on stoque le triplet (ligne, colonne, valeur)\n",
    "\n",
    "Le produit matrice vecteur est une des opérations de base pour tout bibliothèque matricielle. Pour rappel\n",
    "\n",
    "Si $A=(a_{ij})$ est une matrice de type $(m, n)$ et $\\mathbf{b}=(b_{i})$ est un vecteur de type taille $n$, alors leur produit, noté $A\\mathbf{b}=\\mathbf{c}^T$ est un vecteur de taille $m$ donnée par :\n",
    "\n",
    "$$\\forall i: c_{i} = \\sum_{k=1}^n a_{ik}b_{k} = a_{i1}b_{1}+a_{i2}b_{2}+\\cdots+ a_{in}b_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b89ab",
   "metadata": {},
   "source": [
    "## Exercice: benchmarker l'implémentation de la matrice COO\n",
    "Puisque la performance est clé dans ce contexte, nous allons nous efforcer d'obtenir les meilleurs résultats possibles en termes de vitesse. Même si tous les exemples vus dans le cours instrumentent des fonctions, on ne peut pas faire l'économie d'une structure particulière et donc d'une classe. À vous de choisir la meilleure option pour tester et instrumenter vos codes.\n",
    "\n",
    "> Attention, dans cet exercice on va chercher à \"optimiser\" notre représentation de matrice. Cependant, n’oubliez pas:\n",
    "- [Make it work, make it right, make it fast](https://wiki.c2.com/?MakeItWorkMakeItRightMakeItFast) dans cet ordre. On évitera donc l'optimisation prématurée. \n",
    "- Faites fonctionner les classes. \n",
    "- Mettre en place le benchmark.\n",
    "- Optimiser \n",
    "\n",
    "### Benchmark\n",
    "Pour tous les exemples ci-dessous, on comparera l'usage mémoire et le temps de calcul.\n",
    "1. Comparaison avec numpy.ndarray(plein)\n",
    "    - Créer un matrice (pleine) aléatoire de taille $10000 \\times 10000$ et la multiplier avec un vecteur de taille 10000.\n",
    "    - Faire de même pour une matrice creuse avec un remplissage de 1/1000.\n",
    "    \n",
    "1. Pour les matrices creuses:\n",
    "    - Générer une matrice de dimension $10^6 \\times 10^8$ avec $10^7$ entrés non nulles et la multiplier avec un vecteur de taille correspondante.\n",
    "    - Mesurer une fois l'usage mémoire pour `MatCooPure` et `MatCooNumpy`\n",
    "    - Comparer les implémentations de la question suivante.\n",
    "\n",
    "On fera en sorte que les sorties produisent un rapport lisible pour chacun des benchmarks, par exemple en utilisant des f-strings ou un plot.\n",
    "\n",
    "> *Remarque*: Il peut être judicieux (ou non) de placer ces tests dans des fonctions (!mémoire!)\n",
    "\n",
    "### Classe(s) matrice COO\n",
    "> L'utilisation de fichier python séparée semble opportune.\n",
    "\n",
    "Créer\n",
    "1. une classe matrice COO en python pur `MatCooPure`\n",
    "1. une classe matrice COO en python utilisant numpy `MatCooNumpy`\n",
    "Si vous le souhaitez, vous pouvez programmer une classe mère `MatCoo` pour simplifier les appels. Ce n'est cependant pas nécessaire pour notre benchmark.\n",
    "\n",
    "Pour les deux classes, vous programmerez: \n",
    "- une initialisation à au hasard avec comme argument : (n,m, n_non_nul)\n",
    "- une initialisation de la matrice identité (à tester formellement)\n",
    "- un affichage adapté (extrait + dimensions réelles et mémoire) comprenant un test\n",
    "- un produit matrice vecteur naïf (qui fonctionne) avec test\n",
    "- un ou des produits matrice vecteur plus rapides. **Pour ce dernier point:** on pourra au choix coder des méthodes **ou** des fonctions dont le premier argument est une instance de ces classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fa7e5",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128b81a",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94015866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 10**5\n",
    "\n",
    "mat_pl = np.random.randint(10, size = (n, n))\n",
    "vector = np.random.rand(n, 1)\n",
    "result = np.dot(mat_pl, vector) \n",
    "mat_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f626c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f1fb0a38d1ad28da9d4be159e1b6c82ad8432f8d91f6639cd44cacdd2c13c910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
